{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vedangi2610/FHE-project-/blob/master/data_collection/CollectMaxTweets.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G6vSpa805OAU"
      },
      "source": [
        "<h1>Current Data Collection Code</h1>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hB7dCfc6mj1S"
      },
      "source": [
        "import tweepy #https://github.com/tweepy/tweepy\n",
        "import csv\n",
        "import pandas as pd"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "abfqu_uTmlSn"
      },
      "source": [
        "#Twitter API credentials\n",
        "consumer_key = \"kB05ueHmnwXSqQbah9QBETV5s\"\n",
        "consumer_secret = \"8SBnQwZHGthoKIA50231K46j4kiRdLqVs54WXvn3t0h6xYKd0Q\"\n",
        "access_key = \"899207374048710656-J0xFuFaHQ8mv0EJBsXOTxaSAyRjs2UP\"\n",
        "access_secret = \"cvBFKYoW9zUqkIavedyEj8Wte0r2UnXRNCwVJyT0apjmw\""
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yx0h6i89m9V9"
      },
      "source": [
        "def get_all_tweets(screen_name, file_name):\n",
        "    #Twitter only allows access to a users most recent 3240 tweets with this method\n",
        "    \n",
        "    #authorize twitter, initialize tweepy\n",
        "    auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
        "    auth.set_access_token(access_key, access_secret)\n",
        "    api = tweepy.API(auth)\n",
        "    \n",
        "    #initialize a list to hold all the tweepy Tweets\n",
        "    alltweets = []  \n",
        "    \n",
        "    #make initial request for most recent tweets (200 is the maximum allowed count)\n",
        "    new_tweets = api.user_timeline(screen_name = screen_name,count=200)\n",
        "    \n",
        "    #save most recent tweets\n",
        "    alltweets.extend(new_tweets)\n",
        "    \n",
        "    #save the id of the oldest tweet less one\n",
        "    oldest = alltweets[-1].id - 1\n",
        "    \n",
        "    #keep grabbing tweets until there are no tweets left to grab\n",
        "    while len(new_tweets) > 0:\n",
        "        print(f\"getting tweets before {oldest}\")\n",
        "        \n",
        "        #all subsiquent requests use the max_id param to prevent duplicates\n",
        "        new_tweets = api.user_timeline(screen_name = screen_name,count=200,max_id=oldest)\n",
        "        \n",
        "        #save most recent tweets\n",
        "        alltweets.extend(new_tweets)\n",
        "        \n",
        "        #update the id of the oldest tweet less one\n",
        "        oldest = alltweets[-1].id - 1\n",
        "        \n",
        "        print(f\"...{len(alltweets)} tweets downloaded so far\")\n",
        "    \n",
        "    #transform the tweepy tweets into a 2D array that will populate the csv \n",
        "    outtweets = [[tweet.id_str, screen_name, tweet.created_at, tweet.lang, tweet.favorite_count, tweet.retweet_count, tweet.text] for tweet in alltweets]\n",
        "   \n",
        "    '''Code to add to a new file for each screen_name '''\n",
        "#     with open(f'new_{screen_name}_tweets.csv', 'w',  encoding=\"utf-8\") as f:\n",
        "#         writer = csv.writer(f)\n",
        "#         writer.writerow([\"id\",\"username\",\"created_at\",\"lang\",\"favorite_count\",\"retweet_count\",\"text\"])\n",
        "#         writer.writerows(outtweets)\n",
        "    \n",
        "    '''Code for csv file addition'''\n",
        "    # Open/create a file to append data, This will add data to the file Not create a new file each run\n",
        "    file_name = file_name+'.csv'        \n",
        "    csvFile = open(file_name, 'a', encoding=\"utf-8\")\n",
        "    csvWriter = csv.writer(csvFile)\n",
        "    '''To check if file exists'''\n",
        "    try: \n",
        "        pd.read_csv(file_name)\n",
        "    except pd.errors.EmptyDataError:\n",
        "        csvWriter.writerow([\"id\",\"username\",\"created_at\",\"lang\",\"favorite_count\",\"retweet_count\",\"text\"])\n",
        "        \n",
        "    csvWriter.writerows(outtweets)\n",
        "    csvFile.close()\n",
        "\n",
        "    pass\n",
        "\n",
        "\n"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Y8Yvu0w5OAj"
      },
      "source": [
        "def get_tweets_all_topics():\n",
        "    topic=[\"narendramodi\"]\n",
        "    #, \"ShashiTharoor\", \"JoeBiden\", \"AtishiAAP\"]\n",
        "    topic_names=[\"Politics\"]\n",
        "    for topic in topic_names:\n",
        "        for t in topic:\n",
        "            get_all_tweets(t, topic)\n",
        "    "
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zP1HEALsnk9z",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 132
        },
        "outputId": "cf620327-fbac-40a6-9949-196d230ff50d"
      },
      "source": [
        "if __name__ == '__main__':\n",
        "    #pass in the username of the account you want to download\n",
        "    #get_all_tweets(\"weedbiryani\", \"test_csv\")\n",
        "    #get_tweets_all_topics()\n",
        "    topic=[\"narendramodi\"]\n",
        "    #, \"ShashiTharoor\", \"JoeBiden\", \"AtishiAAP\"]\n",
        "    topic_names=[\"Politics\"]\n",
        "    for topic in topic_names:\n",
        "        for t in topic:\n",
        "          try:\n",
        "            get_all_tweets(t, \"politics_csv\")\n",
        "          except Exception, e:\n",
        "            pass\n",
        "    print(\"Done!\")"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-27-517d7c4c180a>\"\u001b[0;36m, line \u001b[0;32m12\u001b[0m\n\u001b[0;31m    except Exception, e:\u001b[0m\n\u001b[0m                    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IoR9r3vB9wpI"
      },
      "source": [
        "\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uKzvVSij5yNo"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}